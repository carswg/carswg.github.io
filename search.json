[
  {
    "objectID": "journalclub/journalclub5.html",
    "href": "journalclub/journalclub5.html",
    "title": "Automated, efficient and model-free inference for randomized clinical trials via data-driven covariate adjustment",
    "section": "",
    "text": "Topic: Automated, efficient and model-free inference for randomized clinical trials via data-driven covariate adjustment\nDatetime: September 13th Friday, 11am-12pm EDT.\nPresenter: Kelly Van Lancker from Ghent University\nZoom link:: https://umich.zoom.us/j/7573650566\nSummary: In May 2023, the U.S. Food and Drug Administration (FDA) released guidance for industry on “Adjustment for Covariates in Randomized Clinical Trials for Drugs and Biological Products”. Covariate adjustment is a statistical analysis method for improving precision and power in clinical trials by adjusting for pre-specified, prognostic baseline variables. Though recommended by the FDA and the European Medicines Agency (EMA), many trials do not exploit the available information in baseline variables or make use only of the baseline measurement of the outcome. This is likely (partly) due to the regulatory mandate to pre-specify baseline covariates for adjustment, leading to challenges in determining appropriate covariates and their functional forms. We will explore the potential of automated data-adaptive methods, such as machine learning algorithms, for covariate adjustment, addressing the challenge of pre-specification. Specifically, our approach allows the use of complex models or machine learning algorithms without compromising the interpretation or validity of the treatment effect estimate and its corresponding standard error, even in the presence of misspecified outcome working models. This contrasts the majority of competing works which assume correct model specification for the validity of standard errors. Our proposed estimators either necessitate ultra-sparsity in the outcome model (which can be relaxed by limiting the number of predictors in the model) or necessitate integration with sample splitting to enhance their performance. As such, we will arrive at simple estimators and standard errors for the marginal treatment effect in randomized clinical trials, which exploit data-adaptive outcome predictions based on prognostic baseline covariates, and have low (or no) bias in finite samples even when those predictions are themselves biased.\nRecording:"
  },
  {
    "objectID": "journalclub/journalclub4.html",
    "href": "journalclub/journalclub4.html",
    "title": "Strategies for Practical and Effective Covariate Adjustment of Continuous Outcomes",
    "section": "",
    "text": "Topic: AStrategies for Practical and Effective Covariate Adjustment of Continuous Outcomes\nDatetime: June 14th Friday, 11am-12pm EDT.\nPresenter: Michel Friesenhahn from Genentech\nZoom link:: https://umich.zoom.us/j/7573650566\nSummary: There has been considerable research that has put covariate adjustment on firm footing, even for use in the primary analysis of confirmatory clinical trials. Several of my colleagues and I saw there was a need to explain the insights generated from this research and to distill them into simple and practical suggestions for implementation. Our recommendations for continuous outcomes when primary interest is in unconditional treatment effect estimands, such as Average Treatment Effects (ATEs), are written up in blog form (https://stats4datascience.com/posts/covariate_adjustment/).\nFor this talk, I will discuss selected proposals from the blog that I think may be of particular interest to the working group, as well as potential areas for future work:\n\nPerformance metrics and their use in analyzing data external to a trial to select and/or construct covariates. In addition, I will discuss how these metrics provide insight into the impacts of Heterogeneous Treatment Effects (HTEs) and strategic implications for sample size determination.\nThe concept of a model budget and suggested rules of thumb to protect the validity of statistical inference when using covariate adjustment.\nSuggestions for constructing the working regression model.\nAccounting for stratified randomization.\nFinally, I will discuss covariate adjustment of longitudinal data with continuous outcomes.\n\nRecording:\n\nSlides: https://drive.google.com/file/d/1ST83aTvH0A40KNusQ6-dg3IqdH3uaN5O/view?usp=drive_link"
  },
  {
    "objectID": "journalclub/journalclub3.html",
    "href": "journalclub/journalclub3.html",
    "title": "A General Form of Covariate Adjustment in Randomized Clinical Trials",
    "section": "",
    "text": "Topic: A General Form of Covariate Adjustment in Randomized Clinical Trials\nDatetime: May 10th Friday, 11am-12pm EDT.\nPresenter: Marlena Bannick from University of Washington\nRecording:\n\nPaper link: https://arxiv.org/abs/2306.10213"
  },
  {
    "objectID": "journalclub/journalclub10.html",
    "href": "journalclub/journalclub10.html",
    "title": "COADVISE: Covariate Adjustment with Variable Selection and Missing Data Imputation in Randomized Controlled Trials",
    "section": "",
    "text": "Topic: COADVISE: Covariate Adjustment with Variable Selection and Missing Data Imputation in Randomized Controlled Trials\nDatetime: March 14th Friday, 11am-12pm ET.\nPresenter: Shu Yang and Yi Liu from North Carolina State University\nSummary: Adjusting for covariates in randomized controlled trials can enhance the credibility and efficiency of average treatment effect estimation. However, managing numerous covariates and their non-linear transformations is challenging, particularly when outcomes and covariates have missing data. In this tutorial, we propose a principled covariate adjustment framework, “COADVISE,” that enables (i) variable selection for covariates most relevant to the outcome, (ii) nonlinear adjustments, and (iii) robust imputation of missing data for both outcomes and covariates. This framework ensures consistent estimates with improved efficiency over unadjusted estimators and provides robust variance estimation, even under outcome model misspecification. We demonstrate efficiency gains through theoretical analysis and conduct extensive simulations to compare alternative variable selection strategies, offering cautionary recommendations. We showcase the framework’s practical utility by applying it to the Best Apnea Interventions for Research trial data from the National Sleep Research Resource. A user-friendly R package, Coadvise, facilitates implementation.\nRecording:"
  },
  {
    "objectID": "journalclub/journalclub2.html",
    "href": "journalclub/journalclub2.html",
    "title": "Variance Estimation for G-computation with Binary Outcomes",
    "section": "",
    "text": "Topic: Variance Estimation for G-computation with Binary Outcomes\nDatetime: April 12th Friday, 11am-12pm EDT.\nPresenter: Dominic Magirr from Novartis (20min presentation about comparisons of different methods)\nDiscussants: Daniel Rubin, Dong Xi, and Ting Ye (20min discussion).\nOpen-floor discussion: 20min.\nRecording:"
  },
  {
    "objectID": "subteam_education.html",
    "href": "subteam_education.html",
    "title": "Education Subteam",
    "section": "",
    "text": "Aim and Plan\nThe goal of the education sub-team is to teach short-courses, develop tutorials and practical guidelines, and collect real case studies.\nTo reach these goals, the education sub-team plans different kinds of activities for 2024:\n\nMonthly meeting (first Monday of the month).\nMake short-course material that will mainly be used to teach short-courses from November 2024 onwards.\nA workshop (e.g., of 90min) on intro to covariate adjustment (November 2024).\n2-3 online blog posts on covariate adjustment. These blog posts will also be disseminated through LinkedIn.\nCollect possible case studies which can be used for tutorials.\n\n\n\nPeople\nCo-leaders: Kelly Van Lancker (Ghent University) and Dominic Magirr (Novartis)\nMembers: Ting Ye, Daniel Rubin, Yanyao Yi, Yu Du, Dong Xi, Hongfei Li, Devan Mehrotra, Andreas Brandt, Olga Kuznetsova, Victoria Johnson, Alex Sverdlov, Kayla Irish"
  },
  {
    "objectID": "journal_club.html",
    "href": "journal_club.html",
    "title": "ASA-BIOP Covariate Adjustment SWG",
    "section": "",
    "text": "The ASA Covariate Adjustment Working Group Journal Club convenes monthly, offering a vibrant forum for discussing the latest findings, challenges, or concepts related to covariate adjustment. Our gatherings alternate between two engaging formats:\n\nA roundtable where members delve into specific questions or issues they’ve encountered, and\nA seminar series featuring presentations on recent scholarly articles by our members or esteemed guest speakers.\n\nThese enriching sessions are held on the second Friday of every month, from 11 am to 12 pm EDT.\nWe warmly welcome and highly value your contributions, including topic suggestions, ideas, or feedback for future Journal Club meetings. Please share your thoughts with Bingkai Wang at bingkai@umich.edu."
  },
  {
    "objectID": "journal_club.html#journal-club",
    "href": "journal_club.html#journal-club",
    "title": "ASA-BIOP Covariate Adjustment SWG",
    "section": "",
    "text": "The ASA Covariate Adjustment Working Group Journal Club convenes monthly, offering a vibrant forum for discussing the latest findings, challenges, or concepts related to covariate adjustment. Our gatherings alternate between two engaging formats:\n\nA roundtable where members delve into specific questions or issues they’ve encountered, and\nA seminar series featuring presentations on recent scholarly articles by our members or esteemed guest speakers.\n\nThese enriching sessions are held on the second Friday of every month, from 11 am to 12 pm EDT.\nWe warmly welcome and highly value your contributions, including topic suggestions, ideas, or feedback for future Journal Club meetings. Please share your thoughts with Bingkai Wang at bingkai@umich.edu."
  },
  {
    "objectID": "journal_club.html#events",
    "href": "journal_club.html#events",
    "title": "ASA-BIOP Covariate Adjustment SWG",
    "section": "Events",
    "text": "Events"
  },
  {
    "objectID": "posts/website_launch.html",
    "href": "posts/website_launch.html",
    "title": "Welcome to ASA BIOP Covariate Adjustment SWG’s Webpage!",
    "section": "",
    "text": "Hello and welcome!\nWe’re excited to share the launch of the ASA BIOP Covariate Adjustment SWG website."
  },
  {
    "objectID": "subteam_advancement.html",
    "href": "subteam_advancement.html",
    "title": "Advancement Subteam",
    "section": "",
    "text": "The overarching goal of the advance sub-team is to develop and disseminate new statistical methods that address emerging challenges in covariate adjustment for randomized clinical trials (RCTs).\nIn the past five years, covariate adjustment has become increasing popular in analyzing RCTs and has also attracted great attention for methodological developments. However, the increasing complexities of real-world RCTs has outpaced the method development, leaving tons of open questions regarding covariate adjustment. For example, it remains not fully clear about the benefit of covariate adjustment and its appropriate implementation given missing data, longitudinal outcomes, time-to-event outcomes, complex trial designs, etc. These important gaps between practice and theory demand continuing efforts to deepen our understanding and develop new tools. As the statistical practice evolves, the advance sub-team aims to stay in the frontline of new techniques, results, and tools, targeting the boundary of knowledge and unopened questions.\nBearing the aim, the advance sub-team plans two kinds of activities:\n\nA monthly journal club to communicate new results regarding covariate adjustment.\nAn online forum for group-members to post/discuss questions and share resources.\n\n\n\nThe journal club takes an online format via zoom meeting and welcomes all members of the working group. Depending on the public interest, external audience can be accommodated later.\nThe journal club can take two formats: (1) roundtable discussion of an issue/question raised by group members; or (2) a seminar of recent papers presented by group members or invited external speakers. All sub-team members are encouraged to bring up roundtable topics and papers of interest through a shared Google doc, and Dr. Bingkai Wang will tentatively take the responsibilities to make schedule, invite and host speakers, and lead discussion. We do not restrict the topic of each meeting as long as it is relevant to covariate adjustment, e.g., a new method, confusions about current results, statistical software, experience sharing, etc. For each journal club meeting, we expect a warm and in-depth discussion such that new thoughts and results can be freely communicated.\n\n\n\nThe online forum serves as a platform for group members to share news, discuss questions, and post resources. In the early stage, a simple Google doc will be used to realize this function, and a formal webpage will be developed later. Dr. Bingkai Wang will tentatively maintain the forum and draft monthly newsletters summarizing the discussions for all group members.\nWe anticipate an informal and friendly forum that puts no pressure in speaking and benefits all readers. The sub-team members are especially encouraged to post thoughts and responses through the forum, aiming to warm up the forum in the early stage.\nBeyond the two activities,we also encourage offline collaborations and connections. We believe the planned activities can be a valuable opportunity to nurture new thoughts, connections, and findings. As a working group gathering worldwide talents and experts of RCTs, we have no doubt on the potential value of this platform and look forward to its powerful impact on the community."
  },
  {
    "objectID": "subteam_advancement.html#journal-club",
    "href": "subteam_advancement.html#journal-club",
    "title": "Advancement Subteam",
    "section": "",
    "text": "The journal club takes an online format via zoom meeting and welcomes all members of the working group. Depending on the public interest, external audience can be accommodated later.\nThe journal club can take two formats: (1) roundtable discussion of an issue/question raised by group members; or (2) a seminar of recent papers presented by group members or invited external speakers. All sub-team members are encouraged to bring up roundtable topics and papers of interest through a shared Google doc, and Dr. Bingkai Wang will tentatively take the responsibilities to make schedule, invite and host speakers, and lead discussion. We do not restrict the topic of each meeting as long as it is relevant to covariate adjustment, e.g., a new method, confusions about current results, statistical software, experience sharing, etc. For each journal club meeting, we expect a warm and in-depth discussion such that new thoughts and results can be freely communicated."
  },
  {
    "objectID": "subteam_advancement.html#online-forum",
    "href": "subteam_advancement.html#online-forum",
    "title": "Advancement Subteam",
    "section": "",
    "text": "The online forum serves as a platform for group members to share news, discuss questions, and post resources. In the early stage, a simple Google doc will be used to realize this function, and a formal webpage will be developed later. Dr. Bingkai Wang will tentatively maintain the forum and draft monthly newsletters summarizing the discussions for all group members.\nWe anticipate an informal and friendly forum that puts no pressure in speaking and benefits all readers. The sub-team members are especially encouraged to post thoughts and responses through the forum, aiming to warm up the forum in the early stage.\nBeyond the two activities,we also encourage offline collaborations and connections. We believe the planned activities can be a valuable opportunity to nurture new thoughts, connections, and findings. As a working group gathering worldwide talents and experts of RCTs, we have no doubt on the potential value of this platform and look forward to its powerful impact on the community."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "“Covariate Adjustment SWG” is a scentific working group of the American Statistical Association (ASA) Biopharmaceutical section (BIOP)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ASA-BIOP Covariate Adjustment SWG",
    "section": "",
    "text": "This is the home page of American Statistical Association (ASA) Biopharmaceutical Section (BIOP) Covariate Adjustment Scientific Working Group (SWG)."
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "People",
    "section": "",
    "text": "Founders and co-chairs: Ye Ting (University of Washington) and Jingyi Liu (Eli Lily)\nAdvisor: Frank Bretz (Novartis), Dan Rubin (FDA), and Andreas Brandt (BfArM)\nSubteam co-leaders:\n\nEducation sub-team: Kelly Van Lancker (Ghent) and Dominic Magirr (Novartis)\nSoftware sub-team: Dong Xi (Gilead) and Yanyao Yi (Eli Lilly)\nStandardization and outreach sub-team: Yu Du (Eli Lilly)\nAdvancement sub-team: Bingkai Wang (University of Michigan)\n\nSecretary: Hongfei Li (Incyte)\n\nMembers\n\n\n\n\n\n\n\n\nFirst Name\nLast Name\nAffiliation\n\n\n\n\nAlan\nWu\nBeigene\n\n\nAlex\nSverdlov\nNovartis\n\n\nAlexander\nPrzybylski\nNovartis\n\n\nAndreas\nBrandt\nBfArM\n\n\nArjun\nSondhi\nFeinstein Institutes for Medical Research\n\n\nBingkai\nWang\nUniversity of Michigan, Biostatistics\n\n\nBingying\nXie\nAstraZeneca\n\n\nCraig\nWang\nNovartis\n\n\nDaniel\nRubin\nFDA\n\n\nDarren\nScott\nAstrazeneca\n\n\nDevan\nMehrotra\nMerck\n\n\nDominic\nMagirr\nNovartis\n\n\nDong\nXi\nGilead\n\n\nFrank\nBretz\nNovartis\n\n\nGregory\nChen\nMerck\n\n\nHongfei\nLi\nIncyte\n\n\nJiajun\nXu\nJohnson & Johnson\n\n\nJiawei\nWei\nNovartis\n\n\nJingyi\nLiu\nEli Lilly\n\n\nJonathan\nChipman\nUniversity of Utah\n\n\nJun\nShao\nUniversity of Wisconsin-Madison, Statistics\n\n\nKayla\nIrish\nUniversity of Washington, Statistics\n\n\nKelly Van\nLancker\nGhent University, Applied Math/CS/Stat\n\n\nKen\nWu\nBeigene\n\n\nLeiya\nHan\nPPD\n\n\nMark\nBaillie\nNovartis\n\n\nMarlena\nBannick\nUniversity of Washington, Biostatistics\n\n\nMike\nFriesenhahn\nRoche/GNE\n\n\nOlga\nKuznetsova\nMerck\n\n\nRay\nLin\nGenentech\n\n\nSarwar\nMozumder\nAstraZeneca\n\n\nSatrajit\nRoychoudhury\nPfizer\n\n\nTing\nYe\nUniversity of Washington, Biostatistics\n\n\nVictoria\nJohnson\nGSK\n\n\nXin\nZhang\nPfizer\n\n\nYanyao\nYi\nEli Lilly\n\n\nYu\nDu\nEli Lilly"
  },
  {
    "objectID": "conference.html",
    "href": "conference.html",
    "title": "Events",
    "section": "",
    "text": "This page intends to list all the conference presentation.\nUnder development"
  },
  {
    "objectID": "subteam_software.html",
    "href": "subteam_software.html",
    "title": "Software Subteam",
    "section": "",
    "text": "To develop and maintain an R package family on covariate adjustment for industry/regulatory/academia with the RobinCar verse (Robust estimation and Inference for Covariate Adjustment in Randomized clinical trials).\n\n\nTo become one of the most comprehensive libraries of existing and future methods on covariate adjustment.\n\nComprehensive coverage of methodologies\nDevelopment version of RobinCar2\n\n\n\n\nTo become one of the standard R packages for the industry/regulatory on covariate adjustment Selected methods with rigorous validation and clear documentation for GxP compliance.\n\nA lite version of RobinCar in terms of methodology coverage\nA more rigorously validated and better documented version of RobinCar, suitable for the GxP environment"
  },
  {
    "objectID": "subteam_software.html#robincar",
    "href": "subteam_software.html#robincar",
    "title": "Software Subteam",
    "section": "",
    "text": "To become one of the most comprehensive libraries of existing and future methods on covariate adjustment.\n\nComprehensive coverage of methodologies\nDevelopment version of RobinCar2"
  },
  {
    "objectID": "subteam_software.html#robincar2",
    "href": "subteam_software.html#robincar2",
    "title": "Software Subteam",
    "section": "",
    "text": "To become one of the standard R packages for the industry/regulatory on covariate adjustment Selected methods with rigorous validation and clear documentation for GxP compliance.\n\nA lite version of RobinCar in terms of methodology coverage\nA more rigorously validated and better documented version of RobinCar, suitable for the GxP environment"
  },
  {
    "objectID": "subteam_standardization.html",
    "href": "subteam_standardization.html",
    "title": "Standardization and Outreach Subteam",
    "section": "",
    "text": "Aim and Plan\n\nWork with other sub-teams to provide recommendations for the appropriate analysis approaches using covariate adjustment with varied endpoints in accordance with the defined estimand framework. Develp comprehensive procedures and best practices in implementing the methods.\n\n1.1.   Continuous endpoints\n1.2.   Binary endpoints\n1.3.   Categorical endpoints\n1.4.   Time to event endpoints\n\nPromote harmonisation of language use with respect to covariate adjustments in clinical trial-related documents. Create a standardized lexicon to maintain consistent terminology and definitions. Create templates for the following documents:\n\n2.1.   Protocol\n2.2.   Statistical Analysis Plan\n2.3.   Clinical Study Report\n\nReach out to raise awareness about the appropriate use of covariate adjustments in the analyses of clinical trials and to promote the products from the working group.\n\n3.1.   Launch dedicated platforms (e.g., linkedin, X) to share insights, best practices, and updates from the working group\n3.2.   Develop a content calendar for regular posts on key topics, updates from recent research, and highlights from industry conferences.\n3.3.   Engage with the wider statistical and clinical community by sharing relevant work, hosting webinars, and participating in conferences/discussions."
  },
  {
    "objectID": "posts/blog_linear_model.html",
    "href": "posts/blog_linear_model.html",
    "title": "Covariate Adjustment for Linear Models: Understanding FDA Advice on Standard Errors",
    "section": "",
    "text": "Please see the website https://carswg.github.io/ for information about the ASA Covariate Adjustment Working Group."
  },
  {
    "objectID": "posts/blog_linear_model.html#treatment-by-covariate-interactions",
    "href": "posts/blog_linear_model.html#treatment-by-covariate-interactions",
    "title": "Covariate Adjustment for Linear Models: Understanding FDA Advice on Standard Errors",
    "section": "Treatment by covariate interactions",
    "text": "Treatment by covariate interactions\nTo understand the right hand column of the two-by-two table, where neither the model-based nor the sandwich estimator would be recommended, we can stay within the framework of a correctly specified working model, \\[Y_i = \\beta_0 + \\beta_1A_i + \\beta_2X_i + \\beta_3A_iX_i + \\epsilon_i,\\]\nwhere \\(\\epsilon_i \\sim N(0, \\sigma^2)\\). At the moment, we are assuming that this model is correctly specified in the sense of having the correct mean model \\(E(Y_i\\mid A_i, X_i) = \\beta_0 + \\beta_1A_i + \\beta_2X_i + \\beta_3A_iX_i\\), in the sense of having the correct variance model \\(\\mathrm{var}(Y_i\\mid A_i, X_i) = \\sigma^2\\), and also in the sense of having the correct distribution. These assumptions will be relaxed later in the post.\nThe first important point is that the parameter \\(\\beta_1\\) does not in general correspond to \\(E_f(Y_i(1) - Y_i(0))\\), so we cannot simply report the maximum likelihood estimate \\(\\hat{\\beta}_1\\). To use the working model to estimate \\(E_f(Y_i(1) - Y_i(0))\\), one option is g-computation (or standardization). As described above, this produces an estimator \\(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3\\).\nThe question remains how do we estimate \\(\\mathrm{var}(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3)\\)?\n\nLaw of total variance\nThe law of total variance (with a correctly specified mean model) says that\n\\[\\begin{equation}\n\\begin{split}\n\\mathrm{var}(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3) &=  E \\left\\lbrace \\mathrm{var}(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3 \\mid \\underline{A}, \\underline{X})\\right\\rbrace + \\mathrm{var}\\left\\lbrace E(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3\\mid \\underline{A}, \\underline{X}) \\right\\rbrace\\\\  &=  \nE \\left\\lbrace \\mathrm{var}(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3 \\mid \\underline{A}, \\underline{X})\\right\\rbrace + \\beta_3^2\\mathrm{var}(\\bar{X})\n\\end{split}\n\\end{equation}\\]\nGiven our assumptions about the correctness of the working model, the first term, \\(E\\left\\lbrace \\mathrm{var}(\\hat{\\beta}_1 + \\bar{X}\\hat{\\beta}_3 \\mid \\underline{A}, \\underline{X})\\right\\rbrace\\), can be consistently estimated via\n\\[(0 ~~~1 ~~~0 ~~~\\bar{x}) \\widehat{\\mathrm{var}}(\\hat{\\beta} \\mid \\underline{A}= \\underline{a}, \\underline{X}= \\underline{x})  \\left( \\begin{array}{c} 0\\\\ 1 \\\\0 \\\\ \\bar{x} \\end{array} \\right),\\qquad\\qquad(\\mathrm{1})\\] where \\(\\widehat{\\mathrm{var}}(\\hat{\\beta} \\mid \\underline{A}= \\underline{a}, \\underline{X}= \\underline{x})\\) is either the standard model-based variance estimator for the maximum likelihood estimator of \\(\\beta\\) (as would typically be produced by default in standard software) in which case (1) represents the “model based” variance estimator in the two-by-two table above, or \\(\\widehat{\\mathrm{var}}(\\hat{\\beta} \\mid \\underline{A}= \\underline{a}, \\underline{X}= \\underline{x})\\) is a sandwich estimator, in which case (1) represents the “sandwich” variance estimator in the two-by-two table. In either case, (1) ignores the second term in the law of total variance, \\(\\beta_3^2\\mathrm{var}(\\bar{X})\\). This is the reason why it is not recommended. Alternative variance estimators based on influence functions, e.g., Tstiatis et al. (2008), Rosenblum and van der Laan (2010), Ye et al. (2022), do take account of this second term.\nWe did not need to talk about misspecified working models in order to demonstrate why the “model-based” and “sandwich” variance estimators are not recommended when the working model contains treatment by covariate interactions. But it is worth saying at this point that the influence function methods remain asymptotically valid when the mean and/or variance model is misspecified.\n\n\nIllustrative example\nAs a demonstration, we would need to simulate multiple (1000, say) trials from the working model above where there is a strong treatment by covariate interaction. For each simulated trial, we would record the estimate of the treatment effect, as well as the estimated variance of the treatment effect estimator according to the three different methods.\nWe’ll use the influence function approach as implemented in Ye et al. (2022) using the R package {robincar}, noting this is the same as previous versions (e.g., Tstiatis et al. (2008), Rosenblum and van der Laan (2010)).\n\nlibrary(sandwich)\nlibrary(RobinCar)\n\nsim_one_trial &lt;- function(n){\n\n  a &lt;- rbinom(n, 1, 0.5)\n  x &lt;- rnorm(n)\n  y &lt;- 1 + a + x + a * x + rnorm(n)\n  dat &lt;- data.frame(y=y,a=factor(a),x=x)\n  \n  \n  fit &lt;- glm(y ~ a * x, data = dat)\n  \n  estimate &lt;- c(t(c(0, 1, 0, mean(x))) %*% fit$coefficients)\n  model_based &lt;- t(c(0, 1, 0, mean(x))) %*% vcov(fit) %*% c(0, 1, 0, mean(x))\n  sandwich &lt;- t(c(0, 1, 0, mean(x))) %*% sandwich::vcovHC(fit) %*% c(0, 1, 0, mean(x))\n  ye &lt;- RobinCar::robincar_linear(dat, \n                                  \"a\", \n                                  \"y\", \n                                  covariate_cols = \"x\", \n                                  adj_method = \"ANHECOVA\", \n                                  contrast_h = \"diff\")$contrast$varcov[1,1]\n  \n  data.frame(estimate = estimate,\n             model_based = model_based, \n             sandwich = sandwich, \n             ye = ye)\n  \n}\n\nresults &lt;- purrr::map_df(rep(200, 1e3), sim_one_trial)\n\nEmpirically, the variance of the point estimates is…\n\nvar(results$estimate)\n\n[1] 0.02753465\n\n\nWe can see that the Ye et al.(2022) method is reasonably consistent with this…\n\nmean(results$ye)\n\n[1] 0.02499644\n\n\n…while this is not the case for the other two methods…\n\nmean(results$model_based)\n\n[1] 0.02020404\n\nmean(results$sandwich)\n\n[1] 0.02064523"
  },
  {
    "objectID": "posts/blog_linear_model.html#homogeneous-working-model",
    "href": "posts/blog_linear_model.html#homogeneous-working-model",
    "title": "Covariate Adjustment for Linear Models: Understanding FDA Advice on Standard Errors",
    "section": "Homogeneous working model",
    "text": "Homogeneous working model\nWe can now move on to the first column of the two-by-two table. In this case, suppose the working model is \\[Y_i = \\beta_0 + \\beta_1A_i + \\beta_2X_i + \\epsilon_i\\] with \\(N(0, \\sigma^2)\\).\nIf the mean model is correctly specified then it is clear that \\(\\beta_1 = E_f(Y_i(1) - Y_i(0))\\). [Although it can also be shown via a lot of algebra (see e.g. the Appendix of Tsiatis et al. (2008)) that the maximum likelihood estimator \\(\\hat{\\beta}_1\\) is consistent for \\(E_f(Y_i(1) - Y_i(0))\\) even when the model is completely misspecified].\nThe question now is how to estimate \\(\\mathrm{var}(\\hat{\\beta}_1)\\)?\nIn contrast to the treatment-covariate interaction case, the law of total variance (with an assumption of a correctly specified mean model) now tells us that we can focus on estimating the conditional variance, \\[\n\\begin{equation}\n\\begin{split}\n\\mathrm{var}(\\hat{\\beta}_1) &=  E \\left\\lbrace \\mathrm{var}(\\hat{\\beta}_1  \\mid \\underline{A}, \\underline{X})\\right\\rbrace + \\mathrm{var}\\left\\lbrace E(\\hat{\\beta}_1\\mid \\underline{A}, \\underline{X}) \\right\\rbrace\\\\  &=  \nE \\left\\lbrace \\mathrm{var}(\\hat{\\beta}_1  \\mid \\underline{A}, \\underline{X})\\right\\rbrace + 0.\n\\end{split}\n\\end{equation}\n\\]\nThere are two options: 1) a completely model-based approach, \\(\\widehat{\\mathrm{var}}_M(\\hat{\\beta}_1 \\mid \\underline{A}= \\underline{a}, \\underline{X}= \\underline{x})\\), as would typically be produced by default in standard software. Or, 2) the well known Huber-White (White, 1980) “sandwich” estimator, \\(\\widehat{\\mathrm{var}}_S(\\hat{\\beta}_1 \\mid \\underline{A}= \\underline{a}, \\underline{X}= \\underline{x})\\).\nIf all the working model assumptions are satisfied, then both (1) and (2) are consistent estimators of \\(\\mathrm{var}(\\hat{\\beta}_1)\\). We could put a provisional tick mark next to all methods in the left-hand column of the two-by-two table. To replace some of those ticks with crosses, we can consider what happens when the variance model in the working model is not correctly specified.\n\nBack to an unadjusted analysis\nActually, we can make things even simpler for ourselves by considering an unadjusted analysis with working model \\[Y_i = \\beta_0 + \\beta_1A_i + \\epsilon_i, \\qquad \\epsilon_i \\sim N(0, \\sigma^2)\\] but where the true model is \\[Y_i = \\beta_0 + \\beta_1A_i + \\epsilon_i, \\qquad \\epsilon_i \\sim \\begin{array}{c} N(0, \\sigma_0^2), ~~A_i = 0 \\\\N(0, \\sigma_1^2), ~~A_i = 1 \\end{array}.\\] When using the misspecified working model, the maximum likelihood estimator for \\(\\mathrm{var}(\\hat{\\beta}_1 \\mid \\underline{A} = \\underline{a})\\) is\n\\[v^{\\mathrm{miss}} =\\frac{\\hat{\\sigma}^2}{n_0} + \\frac{\\hat{\\sigma}^2}{n_1}.\\]\nSubstituting in\n\\[ \\hat{\\sigma}^2 = \\frac{n_0\\hat{\\sigma}_0^2 + n_1\\hat{\\sigma}_1^2}{n_0 + n_1}\\] and rearranging yields\n\\[v^{\\mathrm{miss}} = \\frac{\\hat{\\sigma}_0^2}{n_1} + \\frac{\\hat{\\sigma}_1^2}{n_0},\\] whereas when using the correct true model, the MLE based variance estimator is \\[v^{\\mathrm{true}} =\\frac{\\hat{\\sigma}_0^2}{n_0} + \\frac{\\hat{\\sigma}_1^2}{n_1}.\\] Obviously the two are equivalent under equal allocation, but this is not the case for unequal allocation. We can plot what happens to \\(v^{\\mathrm{miss}}  / v^{\\mathrm{true}}\\) as a function of \\(\\sigma_0 / \\sigma_1\\) for various choices of allocation ratio (Treatment 1: Treatment 0), e.g, 2:1, 1:1 and 1:2 randomization…\n\nsigma_1 &lt;- 1\nn_1 &lt;- 100\nsigma_0 &lt;- seq(0.33, 2, length = 100)\nv_ratio &lt;- function(n_0){(sigma_0^2/n_1+sigma_1^2/n_0)/(sigma_1^2/n_1+sigma_0^2/n_0)}\nplot(sigma_0, v_ratio(n_0 = 50), type = \"l\", xlab = \"sigma_0 / sigma_1\", ylab = \"ratio of variance estimates\")\npoints(sigma_0, v_ratio(n_0 = 100), type = \"l\", col = 2)\npoints(sigma_0, v_ratio(n_0 = 200), type = \"l\", col = 3)\nlegend(1,1.6,c(\"2:1\", \"1:1\", \"1:2\"), lty = c(1,1,1), col = 1:3)\n\n\n\n\n\n\n\n\nThis shows, for example, that if the true variance on treatment 0 is larger than the true variance on treatment 1, and there are more patients on treatment 1, then the estimated model-based variance of \\(\\hat{\\beta}_1\\) based on the misspecified working model will underestimate the true variance of \\(\\hat{\\beta}_1\\).\nThis is the reason why we need to put a cross next to the model-based approach for non-1:1 randomization when using a homogeneous working model. But we can keep a provisional tick when using 1:1 randomization.\n\n\nWhat about the sandwich estimator?\nFor an unadjusted analysis, the sandwich estimator for \\(\\mathrm{var}(\\hat{\\beta}_1)\\) based on the misspecified working model is essentially equivalent to \\(v^{\\mathrm{true}}\\) above. So for this particular example, the sandwich estimator would still work fine. We can keep a provisional tick mark next to the sandwich estimator for both 1:1 and non-1:1 randomization."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blogs",
    "section": "",
    "text": "Covariate Adjustment for Linear Models: Understanding FDA Advice on Standard Errors\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2024\n\n\nASA Covariate Adjustment Working Group Education Subteam\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to ASA BIOP Covariate Adjustment SWG’s Webpage!\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "journalclub/journalclub9.html",
    "href": "journalclub/journalclub9.html",
    "title": "Estimating the efficiency gain of covariate-adjusted analyses in future clinical trials using external data",
    "section": "",
    "text": "Topic: Estimating the efficiency gain of covariate-adjusted analyses in future clinical trials using external data\nDatetime: February 14th 2025 Friday, 11am-12pm ET.\nPresenter: Xiudi Li from University of California, Berkeley\nSummary: We present a framework for using existing external data to identify and estimate the relative efficiency of a covariate-adjusted estimator compared to an unadjusted estimator in a future randomized trial. Under conditions, these relative efficiencies approximate the ratio of sample sizes needed to achieve a desired power. We develop semiparametrically efficient estimators of the relative efficiencies for several treatment effect estimands of interest with either fully or partially observed outcomes, allowing for the application of flexible statistical learning tools to estimate the nuisance functions. We propose an analytic Wald-type confidence interval and a double bootstrap scheme for statistical inference. We demonstrate the performance of the proposed methods through simulation studies and apply these methods to estimate the efficiency gain of covariate adjustment in Covid-19 therapeutic trials.\nRecording:\n\nSlides: https://drive.google.com/file/d/1kZ-ppZM7B2J6jjaxD7zfGONKiYR81bgD/view?usp=sharing"
  },
  {
    "objectID": "journalclub/journalclub1.html",
    "href": "journalclub/journalclub1.html",
    "title": "Discussion on the FDA Guidance for Covariate Adjustment",
    "section": "",
    "text": "Topic: Discussion on the FDA Guidance for Covariate Adjustment\nDatetime: March 15th Friday, 11am-12pm EDT\nHost: Bingkai Wang (UMich)\nDiscussants: Frank Bretz (Novartis), Daniel Rubin (FDA), and Ting Ye (UWashington)\nOpen-floor discussion: 20min.\nZoom link: https://upenn.zoom.us/j/4909817768\nRecording:"
  },
  {
    "objectID": "journalclub/journalclub6.html",
    "href": "journalclub/journalclub6.html",
    "title": "Covariate-Adjusted Randomization Analyzed with Randomization-Based Inference",
    "section": "",
    "text": "Topic: Covariate-Adjusted Randomization Analyzed with Randomization-Based Inference\nDatetime: Oct 11th Friday, 11am-12pm EDT.\nPresenter: Jonathan Chipman from University of Utah\nSummary: Adjusting for covariates in the design and/or analysis can increase the efficiency of a randomized trial. While several model-based strategies for covariate adjustment have been developed—many of which can accommodate covariate-adjusted/adaptive randomization (CAR)—the potential benefits of CAR are less well understood, particularly regarding efficiency gains. Here, we examine the strengths and limitations of design-based covariate adjustment analyzed with randomization-based inference (i.e., CAR+RBI), review traditional and contemporary CAR methods, and provide a case study to assess the efficiency of CAR+RBI strategies. We ask the question: can adjusting for covariates only in the design be as powerful as adjusting for covariates only in the analysis?\nThe case study uses data from the REACH trial (n=512, 12-month continuous outcome with 9 baseline covariates explaining 32% of the outcome variance). We compare the power of CAR+RBI strategies to detect a beneficial treatment effect against that of complete randomization, analyzed with a comparable covariate-adjusted linear model. In this case study, biased-coin minimization CAR+RBI strategies were the most powerful strategies, suggesting that covariate adjustment in the design can be as effective as model-based covariate adjustment. While these findings are case-specific and results may differ across studies, they highlight the importance of further CAR and RBI research and consideration of implementation barriers.\nThis presentation summarizes the following paper, emphasizing the real-world application/case study.\nChipman JJ, Mayberry L, Greevy RA Jr (2023). Rematching on-the-fly: Sequential matched randomization and a case for covariate-adjusted randomization. Stat Med, 42(22), 3981-3995.\nRecording:"
  },
  {
    "objectID": "journalclub/journalclub8.html",
    "href": "journalclub/journalclub8.html",
    "title": "RobinCar: An R Package for Robust Covariate Adjustment for Continuous, Discrete, and Time-to-Event Outcomes in Randomized Clinical Trials",
    "section": "",
    "text": "Topic: RobinCar: An R Package for Robust Covariate Adjustment for Continuous, Discrete, and Time-to-Event Outcomes in Randomized Clinical Trials\nDatetime: December 13th Friday, 11am-12pm ET.\nPresenter: Marlena Bannick from University of Washington\nSummary: Covariate adjustment is a powerful technique that can improve efficiency when estimating treatment effects in randomized clinical trials. We develop a one-stop and user-friendly R package called RobinCar that allows clinical researchers to conveniently and robustly apply covariate adjustment. RobinCar covers covariate adjustment using linear and non-linear working models, and covariate adjustment for time-to-event outcomes. The guiding principles of RobinCar are to provide users with methods that (1) target the same estimand as the unadjusted analysis, (2) do not make any model assumptions beyond what is assumed for an unadjusted analysis, and (3) have robust variance estimation. Importantly, RobinCar takes into account the randomization scheme when constructing the variance estimate (including simple, stratified permuted block, and Pocock and Simon’s minimization). In this talk, we will give an overview of RobinCar, which will include a tour of the functions, and a brief description of the methodologies behind each of the functions. We will also include a discussion of RobinCar2, which is currently being developed by the Software sub-team of the ASA-BIOP Covariate Adjustment Scientific Working Group. Recording:\n\nSlides: https://docs.google.com/presentation/d/1AiublzA9emaoucCmpqVTsr46c1WoHTAC/edit?usp=sharing&ouid=110697570386924275089&rtpof=true&sd=true"
  },
  {
    "objectID": "journalclub/journalclub7.html",
    "href": "journalclub/journalclub7.html",
    "title": "Adjustments with Many Regressors under Covariate-Adaptive Randomizations",
    "section": "",
    "text": "Topic: Adjustments with Many Regressors under Covariate-Adaptive Randomizations\nDatetime: November 8th Friday, 11am-12pm ET.\nPresenter: Yichong Zhang from Singapore Management University\nSummary: Our paper discovers a new trade-off of using regression adjustments (RAs) in causal inference under covariate-adaptive randomizations (CARs). On one hand, RAs can improve the efficiency of causal estimators by incorporating information from covariates that are not used in the randomization. On the other hand, RAs can degrade estimation efficiency due to their estimation errors, which are not asymptotically negligible when the number of regressors is of the same order as the sample size. Ignoring the estimation errors of RAs may result in serious over- rejection of causal inference under the null hypothesis. To address the issue, we construct a new ATE estimator by optimally linearly combining the estimators with and without RAs. We then develop a unified inference theory for this estimator under CARs. It has two features: (1) the Wald test based on it achieves the exact asymptotic size under the null hypothesis, regardless of whether the number of covariates is fixed or diverges no faster than the sample size; and (2) it guarantees weak efficiency improvement over estimators both with and without RAs.\nRecording:"
  }
]